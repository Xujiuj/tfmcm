{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from typing import List, Dict, Any\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import klib as kl\n",
    "import missingno as mns\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "\n",
    "os.environ['KERAS_BACKEND']='tensorflow'\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.rcParams['font.sans-serif'] = ['Kaiti']\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "PIC_PATH = \"../models/image/image1\"\n",
    "DATA_PATH = '../data/data/'\n",
    "RESULT_PATH = '../data/summary/'\n",
    "MODEL_PATH = '../models/model1/'\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "           1_1      1_10      1_11      1_12      1_13      1_14      1_15  \\\n0     0.012602  0.011450 -0.176203 -0.036674 -0.026947  0.014838  0.006234   \n1    -0.003336 -0.016240 -0.024282 -0.035311  0.114516 -0.193881 -0.060875   \n2    -0.006454  0.001249  0.029096  0.016480  0.029189  0.091976 -0.045963   \n3     0.008098 -0.080366 -0.020176  0.026020 -0.058387  0.046606  0.100686   \n4    -0.006628 -0.068707 -0.106401 -0.027133 -0.069611 -0.021457 -0.055905   \n...        ...       ...       ...       ...       ...       ...       ...   \n7995 -1.086638 -0.542362  0.915988  0.225004 -0.002247  0.164577  0.001263   \n7996 -1.255552 -0.406824  0.842080  0.373561 -0.119010  0.028449  0.016179   \n7997 -1.061691 -0.351442  0.427376  0.447158 -0.089820  0.255325  0.128029   \n7998 -1.086465 -0.250882  0.004460  0.526206 -0.110029  0.046606  0.128029   \n7999 -0.910447 -0.128460 -0.348654  0.587537 -0.065120  0.132810 -0.003708   \n\n          1_16      1_17      1_18  ...      8_28      8_29       8_3  \\\n0    -0.530086 -1.707829 -0.679290  ...  0.003356  0.000226  0.000074   \n1    -0.607624 -2.431200 -0.504764  ...  0.004541  0.000528  0.000702   \n2    -0.350338 -2.307193 -0.472616  ...  0.005349  0.001057  0.001358   \n3     0.051451 -1.363366 -0.500171  ...  0.005704  0.001737  0.001979   \n4     0.492009 -0.639995 -0.247568  ...  0.005569  0.002484  0.002494   \n...        ...       ...       ...  ...       ...       ...       ...   \n7995  0.640037  0.455395 -0.614988  ... -0.002688  0.012859 -0.002563   \n7996  0.569547  0.414059 -0.672401  ... -0.002361  0.014742 -0.001448   \n7997  0.280541  0.248717 -0.612691  ... -0.002058  0.016352 -0.000192   \n7998  0.079647  0.538066 -0.727514  ... -0.001722  0.017584  0.001223   \n7999  0.199479  0.916974 -0.711436  ... -0.001292  0.018340  0.002804   \n\n          8_30       8_4       8_5       8_6       8_7       8_8       8_9  \n0    -0.006010  0.009478 -0.067317 -0.008951 -0.018505  0.008764  0.016276  \n1    -0.005237  0.011004 -0.066072 -0.014454 -0.017302  0.004975  0.006080  \n2    -0.004730  0.012247 -0.062780 -0.018934 -0.014487  0.002274 -0.003967  \n3    -0.004410  0.013146 -0.057815 -0.022116 -0.010262  0.000694 -0.013040  \n4    -0.004134  0.013659 -0.051635 -0.023826 -0.004969  0.000092 -0.020482  \n...        ...       ...       ...       ...       ...       ...       ...  \n7995  0.029693  0.009401 -0.025864 -0.027323  0.025959  0.001592  0.013016  \n7996  0.026582  0.011079 -0.031046 -0.042437  0.022254  0.008665  0.008778  \n7997  0.023567  0.012684 -0.034179 -0.056179  0.019695  0.015104  0.004747  \n7998  0.020678  0.014185 -0.034970 -0.067295  0.018402  0.020689  0.001015  \n7999  0.017887  0.015517 -0.033251 -0.074832  0.018388  0.025200 -0.002334  \n\n[8000 rows x 170 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>1_1</th>\n      <th>1_10</th>\n      <th>1_11</th>\n      <th>1_12</th>\n      <th>1_13</th>\n      <th>1_14</th>\n      <th>1_15</th>\n      <th>1_16</th>\n      <th>1_17</th>\n      <th>1_18</th>\n      <th>...</th>\n      <th>8_28</th>\n      <th>8_29</th>\n      <th>8_3</th>\n      <th>8_30</th>\n      <th>8_4</th>\n      <th>8_5</th>\n      <th>8_6</th>\n      <th>8_7</th>\n      <th>8_8</th>\n      <th>8_9</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.012602</td>\n      <td>0.011450</td>\n      <td>-0.176203</td>\n      <td>-0.036674</td>\n      <td>-0.026947</td>\n      <td>0.014838</td>\n      <td>0.006234</td>\n      <td>-0.530086</td>\n      <td>-1.707829</td>\n      <td>-0.679290</td>\n      <td>...</td>\n      <td>0.003356</td>\n      <td>0.000226</td>\n      <td>0.000074</td>\n      <td>-0.006010</td>\n      <td>0.009478</td>\n      <td>-0.067317</td>\n      <td>-0.008951</td>\n      <td>-0.018505</td>\n      <td>0.008764</td>\n      <td>0.016276</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>-0.003336</td>\n      <td>-0.016240</td>\n      <td>-0.024282</td>\n      <td>-0.035311</td>\n      <td>0.114516</td>\n      <td>-0.193881</td>\n      <td>-0.060875</td>\n      <td>-0.607624</td>\n      <td>-2.431200</td>\n      <td>-0.504764</td>\n      <td>...</td>\n      <td>0.004541</td>\n      <td>0.000528</td>\n      <td>0.000702</td>\n      <td>-0.005237</td>\n      <td>0.011004</td>\n      <td>-0.066072</td>\n      <td>-0.014454</td>\n      <td>-0.017302</td>\n      <td>0.004975</td>\n      <td>0.006080</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>-0.006454</td>\n      <td>0.001249</td>\n      <td>0.029096</td>\n      <td>0.016480</td>\n      <td>0.029189</td>\n      <td>0.091976</td>\n      <td>-0.045963</td>\n      <td>-0.350338</td>\n      <td>-2.307193</td>\n      <td>-0.472616</td>\n      <td>...</td>\n      <td>0.005349</td>\n      <td>0.001057</td>\n      <td>0.001358</td>\n      <td>-0.004730</td>\n      <td>0.012247</td>\n      <td>-0.062780</td>\n      <td>-0.018934</td>\n      <td>-0.014487</td>\n      <td>0.002274</td>\n      <td>-0.003967</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.008098</td>\n      <td>-0.080366</td>\n      <td>-0.020176</td>\n      <td>0.026020</td>\n      <td>-0.058387</td>\n      <td>0.046606</td>\n      <td>0.100686</td>\n      <td>0.051451</td>\n      <td>-1.363366</td>\n      <td>-0.500171</td>\n      <td>...</td>\n      <td>0.005704</td>\n      <td>0.001737</td>\n      <td>0.001979</td>\n      <td>-0.004410</td>\n      <td>0.013146</td>\n      <td>-0.057815</td>\n      <td>-0.022116</td>\n      <td>-0.010262</td>\n      <td>0.000694</td>\n      <td>-0.013040</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>-0.006628</td>\n      <td>-0.068707</td>\n      <td>-0.106401</td>\n      <td>-0.027133</td>\n      <td>-0.069611</td>\n      <td>-0.021457</td>\n      <td>-0.055905</td>\n      <td>0.492009</td>\n      <td>-0.639995</td>\n      <td>-0.247568</td>\n      <td>...</td>\n      <td>0.005569</td>\n      <td>0.002484</td>\n      <td>0.002494</td>\n      <td>-0.004134</td>\n      <td>0.013659</td>\n      <td>-0.051635</td>\n      <td>-0.023826</td>\n      <td>-0.004969</td>\n      <td>0.000092</td>\n      <td>-0.020482</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>7995</th>\n      <td>-1.086638</td>\n      <td>-0.542362</td>\n      <td>0.915988</td>\n      <td>0.225004</td>\n      <td>-0.002247</td>\n      <td>0.164577</td>\n      <td>0.001263</td>\n      <td>0.640037</td>\n      <td>0.455395</td>\n      <td>-0.614988</td>\n      <td>...</td>\n      <td>-0.002688</td>\n      <td>0.012859</td>\n      <td>-0.002563</td>\n      <td>0.029693</td>\n      <td>0.009401</td>\n      <td>-0.025864</td>\n      <td>-0.027323</td>\n      <td>0.025959</td>\n      <td>0.001592</td>\n      <td>0.013016</td>\n    </tr>\n    <tr>\n      <th>7996</th>\n      <td>-1.255552</td>\n      <td>-0.406824</td>\n      <td>0.842080</td>\n      <td>0.373561</td>\n      <td>-0.119010</td>\n      <td>0.028449</td>\n      <td>0.016179</td>\n      <td>0.569547</td>\n      <td>0.414059</td>\n      <td>-0.672401</td>\n      <td>...</td>\n      <td>-0.002361</td>\n      <td>0.014742</td>\n      <td>-0.001448</td>\n      <td>0.026582</td>\n      <td>0.011079</td>\n      <td>-0.031046</td>\n      <td>-0.042437</td>\n      <td>0.022254</td>\n      <td>0.008665</td>\n      <td>0.008778</td>\n    </tr>\n    <tr>\n      <th>7997</th>\n      <td>-1.061691</td>\n      <td>-0.351442</td>\n      <td>0.427376</td>\n      <td>0.447158</td>\n      <td>-0.089820</td>\n      <td>0.255325</td>\n      <td>0.128029</td>\n      <td>0.280541</td>\n      <td>0.248717</td>\n      <td>-0.612691</td>\n      <td>...</td>\n      <td>-0.002058</td>\n      <td>0.016352</td>\n      <td>-0.000192</td>\n      <td>0.023567</td>\n      <td>0.012684</td>\n      <td>-0.034179</td>\n      <td>-0.056179</td>\n      <td>0.019695</td>\n      <td>0.015104</td>\n      <td>0.004747</td>\n    </tr>\n    <tr>\n      <th>7998</th>\n      <td>-1.086465</td>\n      <td>-0.250882</td>\n      <td>0.004460</td>\n      <td>0.526206</td>\n      <td>-0.110029</td>\n      <td>0.046606</td>\n      <td>0.128029</td>\n      <td>0.079647</td>\n      <td>0.538066</td>\n      <td>-0.727514</td>\n      <td>...</td>\n      <td>-0.001722</td>\n      <td>0.017584</td>\n      <td>0.001223</td>\n      <td>0.020678</td>\n      <td>0.014185</td>\n      <td>-0.034970</td>\n      <td>-0.067295</td>\n      <td>0.018402</td>\n      <td>0.020689</td>\n      <td>0.001015</td>\n    </tr>\n    <tr>\n      <th>7999</th>\n      <td>-0.910447</td>\n      <td>-0.128460</td>\n      <td>-0.348654</td>\n      <td>0.587537</td>\n      <td>-0.065120</td>\n      <td>0.132810</td>\n      <td>-0.003708</td>\n      <td>0.199479</td>\n      <td>0.916974</td>\n      <td>-0.711436</td>\n      <td>...</td>\n      <td>-0.001292</td>\n      <td>0.018340</td>\n      <td>0.002804</td>\n      <td>0.017887</td>\n      <td>0.015517</td>\n      <td>-0.033251</td>\n      <td>-0.074832</td>\n      <td>0.018388</td>\n      <td>0.025200</td>\n      <td>-0.002334</td>\n    </tr>\n  </tbody>\n</table>\n<p>8000 rows × 170 columns</p>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transform = pd.read_csv(RESULT_PATH + 'transform.csv')\n",
    "transform"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "def read_bins(path: str, res=True) -> Any:\n",
    "    if res:\n",
    "        f = open(RESULT_PATH + path, 'rb')\n",
    "    else:\n",
    "        f = open(path, 'rb')\n",
    "    s = f.read()\n",
    "    return pickle.loads(s)\n",
    "\n",
    "def write_bins(model: Any, path: str, res=True) -> Any:\n",
    "    path = RESULT_PATH + path if res else path\n",
    "    m = pickle.dumps(model)\n",
    "    with open(path, 'wb+') as f:\n",
    "        f.write(m)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "earth = read_bins('earth.list')\n",
    "shed = read_bins('unnatural.list')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "           0          1          2          3          4          5     \\\n1_1    0.031847  -0.011189  -0.019609   0.019685  -0.020076  -0.000898   \n1_10   0.001247  -0.007641  -0.002028  -0.028223  -0.024481   0.002182   \n1_11  -0.018077  -0.000769   0.005312  -0.000301  -0.010124  -0.010592   \n1_12  -0.015064  -0.014596   0.003179   0.006454  -0.011789   0.012067   \n1_13  -0.004527   0.024943   0.007167  -0.011077  -0.013415   0.017458   \n...         ...        ...        ...        ...        ...        ...   \n8_23 -18.703373 -24.892555 -28.146841 -28.462965 -26.189087 -21.945822   \n8_24   6.533483  -0.396517  -7.194654 -13.267302 -18.153183 -21.557693   \n8_25  20.799034   5.738626  -9.456475 -23.552597 -35.564842 -44.826271   \n8_26 -53.410206 -61.589596 -69.321838 -75.982040 -81.187347 -84.861229   \n8_27   9.416552   8.462877   7.138796   5.501653   3.600021   1.482470   \n\n           6          7          8          9     ...       7990       7991  \\\n1_1   -0.001365  -0.006043  -0.005108   0.001909  ...   0.883669   0.428054   \n1_10  -0.013254  -0.001092   0.007796  -0.017464  ...  -0.221415  -0.206446   \n1_11   0.002973   0.005312  -0.005914  -0.019948  ...   0.076414   0.053493   \n1_12  -0.001498  -0.007579  -0.005708  -0.014596  ...  -0.200771  -0.134347   \n1_13   0.020733   0.001554  -0.004995   0.026346  ...   0.053945   0.042718   \n...         ...        ...        ...        ...  ...        ...        ...   \n8_23 -16.497658 -10.621331  -4.996841  -0.139291  ... -19.474800 -21.291332   \n8_24 -23.357693 -23.578184 -22.349949 -19.867302  ... -16.344751 -13.355243   \n8_25 -50.997498 -54.019127 -54.031170 -51.295456  ...  42.800259  46.561687   \n8_26 -87.241020 -88.820816 -90.248573 -92.205917  ... -93.262451 -96.471428   \n8_27  -0.795898  -3.169367  -5.555490  -7.853857  ...  19.517572  10.471857   \n\n           7992       7993       7994       7995       7996       7997  \\\n1_1   -0.079484   0.102949  -0.804071  -2.936200  -3.392283  -2.868840   \n1_10  -0.214398  -0.183993  -0.189138  -0.176508  -0.133005  -0.115230   \n1_11   0.038057   0.067059   0.085770   0.106352   0.097932   0.050687   \n1_12  -0.079617  -0.021145   0.021423   0.074749   0.125737   0.150997   \n1_13   0.013716  -0.006398   0.018394   0.000618  -0.023706  -0.017625   \n...         ...        ...        ...        ...        ...        ...   \n8_23 -22.178679 -22.506433 -22.501944 -22.248474 -21.719902 -20.843985   \n8_24  -9.812792  -5.895536  -1.810831   2.227601   6.016424   9.369366   \n8_25  49.846790  52.468014  54.245770  55.010464  54.616383  52.959850   \n8_26 -91.967552 -80.409592 -62.989391 -41.308983 -17.208982   7.429181   \n8_27   1.168388  -8.128959 -17.135082 -25.541817 -33.014061 -39.193447   \n\n           7998       7999  \n1_1   -2.935732  -2.460470  \n1_10  -0.082953  -0.043660  \n1_11   0.002506  -0.037723  \n1_12   0.178128   0.199178  \n1_13  -0.021835  -0.012479  \n...         ...        ...  \n8_23 -19.569902 -17.927658  \n8_24  12.115640  14.100052  \n8_25  49.998829  45.767811  \n8_26  30.841425  51.489384  \n8_27 -43.725285 -46.303448  \n\n[90 rows x 8000 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>...</th>\n      <th>7990</th>\n      <th>7991</th>\n      <th>7992</th>\n      <th>7993</th>\n      <th>7994</th>\n      <th>7995</th>\n      <th>7996</th>\n      <th>7997</th>\n      <th>7998</th>\n      <th>7999</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1_1</th>\n      <td>0.031847</td>\n      <td>-0.011189</td>\n      <td>-0.019609</td>\n      <td>0.019685</td>\n      <td>-0.020076</td>\n      <td>-0.000898</td>\n      <td>-0.001365</td>\n      <td>-0.006043</td>\n      <td>-0.005108</td>\n      <td>0.001909</td>\n      <td>...</td>\n      <td>0.883669</td>\n      <td>0.428054</td>\n      <td>-0.079484</td>\n      <td>0.102949</td>\n      <td>-0.804071</td>\n      <td>-2.936200</td>\n      <td>-3.392283</td>\n      <td>-2.868840</td>\n      <td>-2.935732</td>\n      <td>-2.460470</td>\n    </tr>\n    <tr>\n      <th>1_10</th>\n      <td>0.001247</td>\n      <td>-0.007641</td>\n      <td>-0.002028</td>\n      <td>-0.028223</td>\n      <td>-0.024481</td>\n      <td>0.002182</td>\n      <td>-0.013254</td>\n      <td>-0.001092</td>\n      <td>0.007796</td>\n      <td>-0.017464</td>\n      <td>...</td>\n      <td>-0.221415</td>\n      <td>-0.206446</td>\n      <td>-0.214398</td>\n      <td>-0.183993</td>\n      <td>-0.189138</td>\n      <td>-0.176508</td>\n      <td>-0.133005</td>\n      <td>-0.115230</td>\n      <td>-0.082953</td>\n      <td>-0.043660</td>\n    </tr>\n    <tr>\n      <th>1_11</th>\n      <td>-0.018077</td>\n      <td>-0.000769</td>\n      <td>0.005312</td>\n      <td>-0.000301</td>\n      <td>-0.010124</td>\n      <td>-0.010592</td>\n      <td>0.002973</td>\n      <td>0.005312</td>\n      <td>-0.005914</td>\n      <td>-0.019948</td>\n      <td>...</td>\n      <td>0.076414</td>\n      <td>0.053493</td>\n      <td>0.038057</td>\n      <td>0.067059</td>\n      <td>0.085770</td>\n      <td>0.106352</td>\n      <td>0.097932</td>\n      <td>0.050687</td>\n      <td>0.002506</td>\n      <td>-0.037723</td>\n    </tr>\n    <tr>\n      <th>1_12</th>\n      <td>-0.015064</td>\n      <td>-0.014596</td>\n      <td>0.003179</td>\n      <td>0.006454</td>\n      <td>-0.011789</td>\n      <td>0.012067</td>\n      <td>-0.001498</td>\n      <td>-0.007579</td>\n      <td>-0.005708</td>\n      <td>-0.014596</td>\n      <td>...</td>\n      <td>-0.200771</td>\n      <td>-0.134347</td>\n      <td>-0.079617</td>\n      <td>-0.021145</td>\n      <td>0.021423</td>\n      <td>0.074749</td>\n      <td>0.125737</td>\n      <td>0.150997</td>\n      <td>0.178128</td>\n      <td>0.199178</td>\n    </tr>\n    <tr>\n      <th>1_13</th>\n      <td>-0.004527</td>\n      <td>0.024943</td>\n      <td>0.007167</td>\n      <td>-0.011077</td>\n      <td>-0.013415</td>\n      <td>0.017458</td>\n      <td>0.020733</td>\n      <td>0.001554</td>\n      <td>-0.004995</td>\n      <td>0.026346</td>\n      <td>...</td>\n      <td>0.053945</td>\n      <td>0.042718</td>\n      <td>0.013716</td>\n      <td>-0.006398</td>\n      <td>0.018394</td>\n      <td>0.000618</td>\n      <td>-0.023706</td>\n      <td>-0.017625</td>\n      <td>-0.021835</td>\n      <td>-0.012479</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>8_23</th>\n      <td>-18.703373</td>\n      <td>-24.892555</td>\n      <td>-28.146841</td>\n      <td>-28.462965</td>\n      <td>-26.189087</td>\n      <td>-21.945822</td>\n      <td>-16.497658</td>\n      <td>-10.621331</td>\n      <td>-4.996841</td>\n      <td>-0.139291</td>\n      <td>...</td>\n      <td>-19.474800</td>\n      <td>-21.291332</td>\n      <td>-22.178679</td>\n      <td>-22.506433</td>\n      <td>-22.501944</td>\n      <td>-22.248474</td>\n      <td>-21.719902</td>\n      <td>-20.843985</td>\n      <td>-19.569902</td>\n      <td>-17.927658</td>\n    </tr>\n    <tr>\n      <th>8_24</th>\n      <td>6.533483</td>\n      <td>-0.396517</td>\n      <td>-7.194654</td>\n      <td>-13.267302</td>\n      <td>-18.153183</td>\n      <td>-21.557693</td>\n      <td>-23.357693</td>\n      <td>-23.578184</td>\n      <td>-22.349949</td>\n      <td>-19.867302</td>\n      <td>...</td>\n      <td>-16.344751</td>\n      <td>-13.355243</td>\n      <td>-9.812792</td>\n      <td>-5.895536</td>\n      <td>-1.810831</td>\n      <td>2.227601</td>\n      <td>6.016424</td>\n      <td>9.369366</td>\n      <td>12.115640</td>\n      <td>14.100052</td>\n    </tr>\n    <tr>\n      <th>8_25</th>\n      <td>20.799034</td>\n      <td>5.738626</td>\n      <td>-9.456475</td>\n      <td>-23.552597</td>\n      <td>-35.564842</td>\n      <td>-44.826271</td>\n      <td>-50.997498</td>\n      <td>-54.019127</td>\n      <td>-54.031170</td>\n      <td>-51.295456</td>\n      <td>...</td>\n      <td>42.800259</td>\n      <td>46.561687</td>\n      <td>49.846790</td>\n      <td>52.468014</td>\n      <td>54.245770</td>\n      <td>55.010464</td>\n      <td>54.616383</td>\n      <td>52.959850</td>\n      <td>49.998829</td>\n      <td>45.767811</td>\n    </tr>\n    <tr>\n      <th>8_26</th>\n      <td>-53.410206</td>\n      <td>-61.589596</td>\n      <td>-69.321838</td>\n      <td>-75.982040</td>\n      <td>-81.187347</td>\n      <td>-84.861229</td>\n      <td>-87.241020</td>\n      <td>-88.820816</td>\n      <td>-90.248573</td>\n      <td>-92.205917</td>\n      <td>...</td>\n      <td>-93.262451</td>\n      <td>-96.471428</td>\n      <td>-91.967552</td>\n      <td>-80.409592</td>\n      <td>-62.989391</td>\n      <td>-41.308983</td>\n      <td>-17.208982</td>\n      <td>7.429181</td>\n      <td>30.841425</td>\n      <td>51.489384</td>\n    </tr>\n    <tr>\n      <th>8_27</th>\n      <td>9.416552</td>\n      <td>8.462877</td>\n      <td>7.138796</td>\n      <td>5.501653</td>\n      <td>3.600021</td>\n      <td>1.482470</td>\n      <td>-0.795898</td>\n      <td>-3.169367</td>\n      <td>-5.555490</td>\n      <td>-7.853857</td>\n      <td>...</td>\n      <td>19.517572</td>\n      <td>10.471857</td>\n      <td>1.168388</td>\n      <td>-8.128959</td>\n      <td>-17.135082</td>\n      <td>-25.541817</td>\n      <td>-33.014061</td>\n      <td>-39.193447</td>\n      <td>-43.725285</td>\n      <td>-46.303448</td>\n    </tr>\n  </tbody>\n</table>\n<p>90 rows × 8000 columns</p>\n</div>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.DataFrame()\n",
    "\n",
    "for i in earth:\n",
    "    train = pd.concat([train, i.T.iloc[:10]])\n",
    "for i in shed:\n",
    "    train = pd.concat([train, i.T.iloc[:20]])\n",
    "train"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "           0          1          2          3          4          5     \\\n1_19   0.004865  -0.017121  -0.003555   0.002058  -0.003555   0.004397   \n1_2    0.016663  -0.002048  -0.007661   0.007308   0.001226   0.018534   \n1_20   0.000327   0.009683  -0.002947  -0.000140   0.006876   0.003134   \n1_3    0.020103   0.006537  -0.002818  -0.002351  -0.020594   0.000456   \n1_4    0.005837   0.023145   0.003030  -0.019423   0.016596  -0.004454   \n...         ...        ...        ...        ...        ...        ...   \n8_5  -56.581928 -55.657642 -53.212746 -49.525192 -44.935604 -39.779888   \n8_6  -19.432631 -28.327196 -35.569153 -40.711327 -43.475456 -43.747631   \n8_7  -33.967102 -32.017540 -27.452972 -20.603409 -12.023408  -2.387321   \n8_8   16.815691  10.192864   5.472429   2.710255   1.658299   1.842864   \n8_9   23.275391   5.198435 -12.615696 -28.700695 -41.896564 -51.436348   \n\n           6          7          8          9     ...       7990       7991  \\\n1_19  -0.011975  -0.005894  -0.004023  -0.009168  ...  -1.050441  -0.923205   \n1_2    0.000759   0.008711   0.008711   0.001226  ...   1.411575   0.802061   \n1_20   0.002666   0.001731  -0.002011   0.006409  ...  -0.028207  -0.068436   \n1_3    0.007005   0.011215  -0.007964   0.008876  ...   0.410229   0.595001   \n1_4    0.005369   0.013789  -0.017084  -0.004454  ...   0.389414   0.197626   \n...         ...        ...        ...        ...  ...        ...        ...   \n8_5  -34.345398 -28.861521 -23.513969 -18.462746  ...   6.644194  -0.747235   \n8_6  -41.566544 -37.108936 -30.667849 -22.635021  ...  34.883457  28.192152   \n8_7    7.625940  17.436592  26.651592  35.110722  ...  76.403763  70.120720   \n8_8    2.688516   3.643951   4.276560   4.325038  ... -55.594746 -46.241917   \n8_9  -56.966782 -58.497654 -56.310261 -50.860695  ...  54.887783  47.968651   \n\n           7992       7993       7994       7995       7996       7997  \\\n1_19  -0.857249  -0.807196  -0.638797  -0.333806   0.034803   0.402943   \n1_2   -0.713537  -1.159329  -0.163431   1.122488   2.000974   1.194994   \n1_20  -0.097906  -0.070775  -0.042240  -0.064694  -0.048321  -0.022594   \n1_3   -0.218464  -1.535257  -0.487903   1.303684   0.883152   0.248846   \n1_4    0.044195  -0.141981  -0.280910  -0.291669  -0.199985   0.020338   \n...         ...        ...        ...        ...        ...        ...   \n8_5   -7.911929 -14.644786 -20.699072 -25.795603 -29.644175 -31.971317   \n8_6   15.495848  -2.578500 -24.737413 -49.127632 -73.555237 -95.766106   \n8_7   62.356373  53.907246  45.582462  38.119202  32.112026  27.962679   \n8_8  -34.735180 -21.981701  -8.764092   4.280690  16.642647  27.897211   \n8_9   40.608437  32.969738  25.212347  17.495827   9.981479   2.834087   \n\n            7998        7999  \n1_19    0.706531    1.001698  \n1_2    -0.888954   -1.931161  \n1_20   -0.016513    0.008747  \n1_3    -0.528132   -1.347678  \n1_4     0.284164    0.463791  \n...          ...         ...  \n8_5   -32.558460  -31.282133  \n8_6  -113.732628 -125.915459  \n8_7    25.867680   25.843983  \n8_8    37.658298   45.543083  \n8_9    -3.782435   -9.720043  \n\n[80 rows x 8000 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>...</th>\n      <th>7990</th>\n      <th>7991</th>\n      <th>7992</th>\n      <th>7993</th>\n      <th>7994</th>\n      <th>7995</th>\n      <th>7996</th>\n      <th>7997</th>\n      <th>7998</th>\n      <th>7999</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1_19</th>\n      <td>0.004865</td>\n      <td>-0.017121</td>\n      <td>-0.003555</td>\n      <td>0.002058</td>\n      <td>-0.003555</td>\n      <td>0.004397</td>\n      <td>-0.011975</td>\n      <td>-0.005894</td>\n      <td>-0.004023</td>\n      <td>-0.009168</td>\n      <td>...</td>\n      <td>-1.050441</td>\n      <td>-0.923205</td>\n      <td>-0.857249</td>\n      <td>-0.807196</td>\n      <td>-0.638797</td>\n      <td>-0.333806</td>\n      <td>0.034803</td>\n      <td>0.402943</td>\n      <td>0.706531</td>\n      <td>1.001698</td>\n    </tr>\n    <tr>\n      <th>1_2</th>\n      <td>0.016663</td>\n      <td>-0.002048</td>\n      <td>-0.007661</td>\n      <td>0.007308</td>\n      <td>0.001226</td>\n      <td>0.018534</td>\n      <td>0.000759</td>\n      <td>0.008711</td>\n      <td>0.008711</td>\n      <td>0.001226</td>\n      <td>...</td>\n      <td>1.411575</td>\n      <td>0.802061</td>\n      <td>-0.713537</td>\n      <td>-1.159329</td>\n      <td>-0.163431</td>\n      <td>1.122488</td>\n      <td>2.000974</td>\n      <td>1.194994</td>\n      <td>-0.888954</td>\n      <td>-1.931161</td>\n    </tr>\n    <tr>\n      <th>1_20</th>\n      <td>0.000327</td>\n      <td>0.009683</td>\n      <td>-0.002947</td>\n      <td>-0.000140</td>\n      <td>0.006876</td>\n      <td>0.003134</td>\n      <td>0.002666</td>\n      <td>0.001731</td>\n      <td>-0.002011</td>\n      <td>0.006409</td>\n      <td>...</td>\n      <td>-0.028207</td>\n      <td>-0.068436</td>\n      <td>-0.097906</td>\n      <td>-0.070775</td>\n      <td>-0.042240</td>\n      <td>-0.064694</td>\n      <td>-0.048321</td>\n      <td>-0.022594</td>\n      <td>-0.016513</td>\n      <td>0.008747</td>\n    </tr>\n    <tr>\n      <th>1_3</th>\n      <td>0.020103</td>\n      <td>0.006537</td>\n      <td>-0.002818</td>\n      <td>-0.002351</td>\n      <td>-0.020594</td>\n      <td>0.000456</td>\n      <td>0.007005</td>\n      <td>0.011215</td>\n      <td>-0.007964</td>\n      <td>0.008876</td>\n      <td>...</td>\n      <td>0.410229</td>\n      <td>0.595001</td>\n      <td>-0.218464</td>\n      <td>-1.535257</td>\n      <td>-0.487903</td>\n      <td>1.303684</td>\n      <td>0.883152</td>\n      <td>0.248846</td>\n      <td>-0.528132</td>\n      <td>-1.347678</td>\n    </tr>\n    <tr>\n      <th>1_4</th>\n      <td>0.005837</td>\n      <td>0.023145</td>\n      <td>0.003030</td>\n      <td>-0.019423</td>\n      <td>0.016596</td>\n      <td>-0.004454</td>\n      <td>0.005369</td>\n      <td>0.013789</td>\n      <td>-0.017084</td>\n      <td>-0.004454</td>\n      <td>...</td>\n      <td>0.389414</td>\n      <td>0.197626</td>\n      <td>0.044195</td>\n      <td>-0.141981</td>\n      <td>-0.280910</td>\n      <td>-0.291669</td>\n      <td>-0.199985</td>\n      <td>0.020338</td>\n      <td>0.284164</td>\n      <td>0.463791</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>8_5</th>\n      <td>-56.581928</td>\n      <td>-55.657642</td>\n      <td>-53.212746</td>\n      <td>-49.525192</td>\n      <td>-44.935604</td>\n      <td>-39.779888</td>\n      <td>-34.345398</td>\n      <td>-28.861521</td>\n      <td>-23.513969</td>\n      <td>-18.462746</td>\n      <td>...</td>\n      <td>6.644194</td>\n      <td>-0.747235</td>\n      <td>-7.911929</td>\n      <td>-14.644786</td>\n      <td>-20.699072</td>\n      <td>-25.795603</td>\n      <td>-29.644175</td>\n      <td>-31.971317</td>\n      <td>-32.558460</td>\n      <td>-31.282133</td>\n    </tr>\n    <tr>\n      <th>8_6</th>\n      <td>-19.432631</td>\n      <td>-28.327196</td>\n      <td>-35.569153</td>\n      <td>-40.711327</td>\n      <td>-43.475456</td>\n      <td>-43.747631</td>\n      <td>-41.566544</td>\n      <td>-37.108936</td>\n      <td>-30.667849</td>\n      <td>-22.635021</td>\n      <td>...</td>\n      <td>34.883457</td>\n      <td>28.192152</td>\n      <td>15.495848</td>\n      <td>-2.578500</td>\n      <td>-24.737413</td>\n      <td>-49.127632</td>\n      <td>-73.555237</td>\n      <td>-95.766106</td>\n      <td>-113.732628</td>\n      <td>-125.915459</td>\n    </tr>\n    <tr>\n      <th>8_7</th>\n      <td>-33.967102</td>\n      <td>-32.017540</td>\n      <td>-27.452972</td>\n      <td>-20.603409</td>\n      <td>-12.023408</td>\n      <td>-2.387321</td>\n      <td>7.625940</td>\n      <td>17.436592</td>\n      <td>26.651592</td>\n      <td>35.110722</td>\n      <td>...</td>\n      <td>76.403763</td>\n      <td>70.120720</td>\n      <td>62.356373</td>\n      <td>53.907246</td>\n      <td>45.582462</td>\n      <td>38.119202</td>\n      <td>32.112026</td>\n      <td>27.962679</td>\n      <td>25.867680</td>\n      <td>25.843983</td>\n    </tr>\n    <tr>\n      <th>8_8</th>\n      <td>16.815691</td>\n      <td>10.192864</td>\n      <td>5.472429</td>\n      <td>2.710255</td>\n      <td>1.658299</td>\n      <td>1.842864</td>\n      <td>2.688516</td>\n      <td>3.643951</td>\n      <td>4.276560</td>\n      <td>4.325038</td>\n      <td>...</td>\n      <td>-55.594746</td>\n      <td>-46.241917</td>\n      <td>-34.735180</td>\n      <td>-21.981701</td>\n      <td>-8.764092</td>\n      <td>4.280690</td>\n      <td>16.642647</td>\n      <td>27.897211</td>\n      <td>37.658298</td>\n      <td>45.543083</td>\n    </tr>\n    <tr>\n      <th>8_9</th>\n      <td>23.275391</td>\n      <td>5.198435</td>\n      <td>-12.615696</td>\n      <td>-28.700695</td>\n      <td>-41.896564</td>\n      <td>-51.436348</td>\n      <td>-56.966782</td>\n      <td>-58.497654</td>\n      <td>-56.310261</td>\n      <td>-50.860695</td>\n      <td>...</td>\n      <td>54.887783</td>\n      <td>47.968651</td>\n      <td>40.608437</td>\n      <td>32.969738</td>\n      <td>25.212347</td>\n      <td>17.495827</td>\n      <td>9.981479</td>\n      <td>2.834087</td>\n      <td>-3.782435</td>\n      <td>-9.720043</td>\n    </tr>\n  </tbody>\n</table>\n<p>80 rows × 8000 columns</p>\n</div>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.DataFrame()\n",
    "\n",
    "for i in earth:\n",
    "    test = pd.concat([test, i.T.iloc[10:]])\n",
    "for i in shed:\n",
    "    test = pd.concat([test, i.T.iloc[20:]])\n",
    "test"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "def metrics_score(y_true, y_pred):\n",
    "    return [\n",
    "        precision_score(y_true, y_pred),\n",
    "        recall_score(y_true, y_pred),\n",
    "        f1_score(y_true, y_pred),\n",
    "        accuracy_score(y_true, y_pred)\n",
    "    ]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "270 ms ± 75.7 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>: [1.0, 0.8, 0.888888888888889, 0.975]\n",
      "14.6 s ± 1.42 s per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "<class 'sklearn.ensemble._gb.GradientBoostingClassifier'>: [1.0, 0.7, 0.8235294117647058, 0.9625]\n",
      "185 ms ± 8.99 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>: [1.0, 1.0, 1.0, 1.0]\n",
      "47 ms ± 547 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "<class 'sklearn.svm._classes.SVC'>: [1.0, 0.9, 0.9473684210526316, 0.9875]\n"
     ]
    }
   ],
   "source": [
    "for model in [DecisionTreeClassifier(random_state=42), GradientBoostingClassifier(random_state=42),\n",
    "              RandomForestClassifier(random_state=42), SVC(random_state=42)]:\n",
    "    %timeit model.fit(train, [0] * 70 + [1] * 20)\n",
    "    pre = model.predict(test)\n",
    "    print(str(model.__class__) + ': ' + str(metrics_score([0] * 70 + [1] * 10, pre)))\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(.99)\n",
    "p_train = pca.fit_transform(train)\n",
    "p_test = pca.transform(test)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "564 µs ± 112 µs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>: [1.0, 0.9, 0.9473684210526316, 0.9875]\n",
      "41.9 ms ± 552 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "<class 'sklearn.ensemble._gb.GradientBoostingClassifier'>: [1.0, 0.6, 0.7499999999999999, 0.95]\n",
      "85.7 ms ± 1.16 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>: [1.0, 1.0, 1.0, 1.0]\n",
      "421 µs ± 10.7 µs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n",
      "<class 'sklearn.svm._classes.SVC'>: [1.0, 0.9, 0.9473684210526316, 0.9875]\n"
     ]
    }
   ],
   "source": [
    "for model in [DecisionTreeClassifier(random_state=42), GradientBoostingClassifier(random_state=42),\n",
    "              RandomForestClassifier(random_state=42), SVC(random_state=42)]:\n",
    "    %timeit model.fit(p_train, [0] * 70 + [1] * 20)\n",
    "    pre = model.predict(p_test)\n",
    "    print(str(model.__class__) + ': ' + str(metrics_score([0] * 70 + [1] * 10, pre)))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/32\n",
      "3/3 [==============================] - 7s 2s/step - loss: 1.3363 - accuracy: 0.6556 - precision_1: 0.3878 - recall_1: 0.9500\n",
      "Epoch 2/32\n",
      "3/3 [==============================] - 4s 1s/step - loss: 0.1133 - accuracy: 0.9556 - precision_1: 0.8333 - recall_1: 1.0000\n",
      "Epoch 3/32\n",
      "3/3 [==============================] - 4s 1s/step - loss: 0.0592 - accuracy: 0.9889 - precision_1: 0.9524 - recall_1: 1.0000\n",
      "Epoch 4/32\n",
      "3/3 [==============================] - 4s 1s/step - loss: 0.0194 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000\n",
      "Epoch 5/32\n",
      "3/3 [==============================] - 4s 1s/step - loss: 0.0038 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000\n",
      "Epoch 6/32\n",
      "3/3 [==============================] - 4s 1s/step - loss: 0.0012 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000\n",
      "Epoch 7/32\n",
      "3/3 [==============================] - 4s 1s/step - loss: 4.6980e-04 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000\n",
      "Epoch 8/32\n",
      "3/3 [==============================] - 4s 1s/step - loss: 2.9842e-04 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000\n",
      "Epoch 9/32\n",
      "3/3 [==============================] - 4s 1s/step - loss: 1.8950e-04 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000\n",
      "Epoch 10/32\n",
      "3/3 [==============================] - 5s 2s/step - loss: 1.2711e-04 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000\n",
      "Epoch 11/32\n",
      "3/3 [==============================] - 4s 1s/step - loss: 3.2370 - accuracy: 0.8222 - precision_1: 0.5588 - recall_1: 0.9500\n",
      "Epoch 12/32\n",
      "3/3 [==============================] - 5s 2s/step - loss: 0.1600 - accuracy: 0.9111 - precision_1: 0.7143 - recall_1: 1.0000\n",
      "Epoch 13/32\n",
      "3/3 [==============================] - 4s 1s/step - loss: 0.0840 - accuracy: 0.9556 - precision_1: 0.8333 - recall_1: 1.0000\n",
      "Epoch 14/32\n",
      "3/3 [==============================] - 4s 1s/step - loss: 0.0664 - accuracy: 0.9778 - precision_1: 0.9091 - recall_1: 1.0000\n",
      "Epoch 15/32\n",
      "3/3 [==============================] - 4s 1s/step - loss: 0.0539 - accuracy: 0.9667 - precision_1: 0.8696 - recall_1: 1.0000\n",
      "Epoch 16/32\n",
      "3/3 [==============================] - 4s 1s/step - loss: 0.0484 - accuracy: 0.9778 - precision_1: 0.9091 - recall_1: 1.0000\n",
      "Epoch 17/32\n",
      "3/3 [==============================] - 4s 1s/step - loss: 0.0408 - accuracy: 0.9778 - precision_1: 0.9091 - recall_1: 1.0000\n",
      "Epoch 18/32\n",
      "3/3 [==============================] - 4s 1s/step - loss: 0.0328 - accuracy: 0.9778 - precision_1: 0.9091 - recall_1: 1.0000\n",
      "Epoch 19/32\n",
      "3/3 [==============================] - 4s 1s/step - loss: 0.0281 - accuracy: 0.9889 - precision_1: 0.9524 - recall_1: 1.0000\n",
      "Epoch 20/32\n",
      "3/3 [==============================] - 4s 1s/step - loss: 0.0249 - accuracy: 0.9889 - precision_1: 0.9524 - recall_1: 1.0000\n",
      "Epoch 21/32\n",
      "3/3 [==============================] - 4s 1s/step - loss: 0.0201 - accuracy: 0.9889 - precision_1: 0.9524 - recall_1: 1.0000\n",
      "Epoch 22/32\n",
      "3/3 [==============================] - 4s 1s/step - loss: 0.0174 - accuracy: 0.9889 - precision_1: 0.9524 - recall_1: 1.0000\n",
      "Epoch 23/32\n",
      "3/3 [==============================] - 4s 1s/step - loss: 0.0130 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000\n",
      "Epoch 24/32\n",
      "3/3 [==============================] - 4s 1s/step - loss: 0.0087 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000\n",
      "Epoch 25/32\n",
      "3/3 [==============================] - 4s 1s/step - loss: 0.0064 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000\n",
      "Epoch 26/32\n",
      "3/3 [==============================] - 4s 1s/step - loss: 0.0050 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000\n",
      "Epoch 27/32\n",
      "3/3 [==============================] - 4s 1s/step - loss: 0.0035 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000\n",
      "Epoch 28/32\n",
      "3/3 [==============================] - 4s 1s/step - loss: 0.0023 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000\n",
      "Epoch 29/32\n",
      "3/3 [==============================] - 4s 1s/step - loss: 0.0016 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000\n",
      "Epoch 30/32\n",
      "3/3 [==============================] - 4s 1s/step - loss: 0.0011 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000\n",
      "Epoch 31/32\n",
      "3/3 [==============================] - 4s 1s/step - loss: 7.8998e-04 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000\n",
      "Epoch 32/32\n",
      "3/3 [==============================] - 4s 1s/step - loss: 5.2999e-04 - accuracy: 1.0000 - precision_1: 1.0000 - recall_1: 1.0000\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import *\n",
    "from keras.models import Sequential\n",
    "from tcn import TCN\n",
    "from keras.metrics import *\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv1D(32, 31, activation='relu', input_shape=(8000, 1)))\n",
    "model.add(Dropout(.3))\n",
    "model.add(Conv1D(32, 31, activation='relu'))\n",
    "model.add(Dropout(.3))\n",
    "model.add(Conv1D(32, 31, activation='relu'))\n",
    "model.add(MaxPooling1D(5))\n",
    "model.add(Conv1D(32, 31, activation='relu'))\n",
    "model.add(Dropout(.3))\n",
    "model.add(Conv1D(32, 31, activation='relu'))\n",
    "model.add(Dropout(.3))\n",
    "model.add(Conv1D(32, 31, activation='relu'))\n",
    "model.add(MaxPooling1D(5))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', metrics=['accuracy', Precision(), Recall()])\n",
    "hist = model.fit(train.to_numpy().reshape(-1, 8000, 1), np.array([0] * 70 + [1] * 20).reshape(-1, 1), epochs=32)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "[<matplotlib.lines.Line2D at 0x267261e1a60>]"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(hist.history['loss'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 108ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": "[1.0, 1.0, 1.0, 1.0]"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre = model.predict(test)[:, 0]\n",
    "metrics_score([0] * 70 + [1] * 10, np.round(pre))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "<AxesSubplot:title={'center':'Confusion Matrix'}, xlabel='Predicted label', ylabel='True label'>"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 2 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from scikitplot import *\n",
    "\n",
    "metrics.plot_confusion_matrix([0] * 70 + [1] * 10, np.round(pre))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "           0          1          2          3          4          5     \\\n1_1    0.031847  -0.011189  -0.019609   0.019685  -0.020076  -0.000898   \n1_10   0.001247  -0.007641  -0.002028  -0.028223  -0.024481   0.002182   \n1_11  -0.018077  -0.000769   0.005312  -0.000301  -0.010124  -0.010592   \n1_12  -0.015064  -0.014596   0.003179   0.006454  -0.011789   0.012067   \n1_13  -0.004527   0.024943   0.007167  -0.011077  -0.013415   0.017458   \n...         ...        ...        ...        ...        ...        ...   \n8_5  -56.581928 -55.657642 -53.212746 -49.525192 -44.935604 -39.779888   \n8_6  -19.432631 -28.327196 -35.569153 -40.711327 -43.475456 -43.747631   \n8_7  -33.967102 -32.017540 -27.452972 -20.603409 -12.023408  -2.387321   \n8_8   16.815691  10.192864   5.472429   2.710255   1.658299   1.842864   \n8_9   23.275391   5.198435 -12.615696 -28.700695 -41.896564 -51.436348   \n\n           6          7          8          9     ...       7990       7991  \\\n1_1   -0.001365  -0.006043  -0.005108   0.001909  ...   0.883669   0.428054   \n1_10  -0.013254  -0.001092   0.007796  -0.017464  ...  -0.221415  -0.206446   \n1_11   0.002973   0.005312  -0.005914  -0.019948  ...   0.076414   0.053493   \n1_12  -0.001498  -0.007579  -0.005708  -0.014596  ...  -0.200771  -0.134347   \n1_13   0.020733   0.001554  -0.004995   0.026346  ...   0.053945   0.042718   \n...         ...        ...        ...        ...  ...        ...        ...   \n8_5  -34.345398 -28.861521 -23.513969 -18.462746  ...   6.644194  -0.747235   \n8_6  -41.566544 -37.108936 -30.667849 -22.635021  ...  34.883457  28.192152   \n8_7    7.625940  17.436592  26.651592  35.110722  ...  76.403763  70.120720   \n8_8    2.688516   3.643951   4.276560   4.325038  ... -55.594746 -46.241917   \n8_9  -56.966782 -58.497654 -56.310261 -50.860695  ...  54.887783  47.968651   \n\n           7992       7993       7994       7995       7996       7997  \\\n1_1   -0.079484   0.102949  -0.804071  -2.936200  -3.392283  -2.868840   \n1_10  -0.214398  -0.183993  -0.189138  -0.176508  -0.133005  -0.115230   \n1_11   0.038057   0.067059   0.085770   0.106352   0.097932   0.050687   \n1_12  -0.079617  -0.021145   0.021423   0.074749   0.125737   0.150997   \n1_13   0.013716  -0.006398   0.018394   0.000618  -0.023706  -0.017625   \n...         ...        ...        ...        ...        ...        ...   \n8_5   -7.911929 -14.644786 -20.699072 -25.795603 -29.644175 -31.971317   \n8_6   15.495848  -2.578500 -24.737413 -49.127632 -73.555237 -95.766106   \n8_7   62.356373  53.907246  45.582462  38.119202  32.112026  27.962679   \n8_8  -34.735180 -21.981701  -8.764092   4.280690  16.642647  27.897211   \n8_9   40.608437  32.969738  25.212347  17.495827   9.981479   2.834087   \n\n            7998        7999  \n1_1    -2.935732   -2.460470  \n1_10   -0.082953   -0.043660  \n1_11    0.002506   -0.037723  \n1_12    0.178128    0.199178  \n1_13   -0.021835   -0.012479  \n...          ...         ...  \n8_5   -32.558460  -31.282133  \n8_6  -113.732628 -125.915459  \n8_7    25.867680   25.843983  \n8_8    37.658298   45.543083  \n8_9    -3.782435   -9.720043  \n\n[170 rows x 8000 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>...</th>\n      <th>7990</th>\n      <th>7991</th>\n      <th>7992</th>\n      <th>7993</th>\n      <th>7994</th>\n      <th>7995</th>\n      <th>7996</th>\n      <th>7997</th>\n      <th>7998</th>\n      <th>7999</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1_1</th>\n      <td>0.031847</td>\n      <td>-0.011189</td>\n      <td>-0.019609</td>\n      <td>0.019685</td>\n      <td>-0.020076</td>\n      <td>-0.000898</td>\n      <td>-0.001365</td>\n      <td>-0.006043</td>\n      <td>-0.005108</td>\n      <td>0.001909</td>\n      <td>...</td>\n      <td>0.883669</td>\n      <td>0.428054</td>\n      <td>-0.079484</td>\n      <td>0.102949</td>\n      <td>-0.804071</td>\n      <td>-2.936200</td>\n      <td>-3.392283</td>\n      <td>-2.868840</td>\n      <td>-2.935732</td>\n      <td>-2.460470</td>\n    </tr>\n    <tr>\n      <th>1_10</th>\n      <td>0.001247</td>\n      <td>-0.007641</td>\n      <td>-0.002028</td>\n      <td>-0.028223</td>\n      <td>-0.024481</td>\n      <td>0.002182</td>\n      <td>-0.013254</td>\n      <td>-0.001092</td>\n      <td>0.007796</td>\n      <td>-0.017464</td>\n      <td>...</td>\n      <td>-0.221415</td>\n      <td>-0.206446</td>\n      <td>-0.214398</td>\n      <td>-0.183993</td>\n      <td>-0.189138</td>\n      <td>-0.176508</td>\n      <td>-0.133005</td>\n      <td>-0.115230</td>\n      <td>-0.082953</td>\n      <td>-0.043660</td>\n    </tr>\n    <tr>\n      <th>1_11</th>\n      <td>-0.018077</td>\n      <td>-0.000769</td>\n      <td>0.005312</td>\n      <td>-0.000301</td>\n      <td>-0.010124</td>\n      <td>-0.010592</td>\n      <td>0.002973</td>\n      <td>0.005312</td>\n      <td>-0.005914</td>\n      <td>-0.019948</td>\n      <td>...</td>\n      <td>0.076414</td>\n      <td>0.053493</td>\n      <td>0.038057</td>\n      <td>0.067059</td>\n      <td>0.085770</td>\n      <td>0.106352</td>\n      <td>0.097932</td>\n      <td>0.050687</td>\n      <td>0.002506</td>\n      <td>-0.037723</td>\n    </tr>\n    <tr>\n      <th>1_12</th>\n      <td>-0.015064</td>\n      <td>-0.014596</td>\n      <td>0.003179</td>\n      <td>0.006454</td>\n      <td>-0.011789</td>\n      <td>0.012067</td>\n      <td>-0.001498</td>\n      <td>-0.007579</td>\n      <td>-0.005708</td>\n      <td>-0.014596</td>\n      <td>...</td>\n      <td>-0.200771</td>\n      <td>-0.134347</td>\n      <td>-0.079617</td>\n      <td>-0.021145</td>\n      <td>0.021423</td>\n      <td>0.074749</td>\n      <td>0.125737</td>\n      <td>0.150997</td>\n      <td>0.178128</td>\n      <td>0.199178</td>\n    </tr>\n    <tr>\n      <th>1_13</th>\n      <td>-0.004527</td>\n      <td>0.024943</td>\n      <td>0.007167</td>\n      <td>-0.011077</td>\n      <td>-0.013415</td>\n      <td>0.017458</td>\n      <td>0.020733</td>\n      <td>0.001554</td>\n      <td>-0.004995</td>\n      <td>0.026346</td>\n      <td>...</td>\n      <td>0.053945</td>\n      <td>0.042718</td>\n      <td>0.013716</td>\n      <td>-0.006398</td>\n      <td>0.018394</td>\n      <td>0.000618</td>\n      <td>-0.023706</td>\n      <td>-0.017625</td>\n      <td>-0.021835</td>\n      <td>-0.012479</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>8_5</th>\n      <td>-56.581928</td>\n      <td>-55.657642</td>\n      <td>-53.212746</td>\n      <td>-49.525192</td>\n      <td>-44.935604</td>\n      <td>-39.779888</td>\n      <td>-34.345398</td>\n      <td>-28.861521</td>\n      <td>-23.513969</td>\n      <td>-18.462746</td>\n      <td>...</td>\n      <td>6.644194</td>\n      <td>-0.747235</td>\n      <td>-7.911929</td>\n      <td>-14.644786</td>\n      <td>-20.699072</td>\n      <td>-25.795603</td>\n      <td>-29.644175</td>\n      <td>-31.971317</td>\n      <td>-32.558460</td>\n      <td>-31.282133</td>\n    </tr>\n    <tr>\n      <th>8_6</th>\n      <td>-19.432631</td>\n      <td>-28.327196</td>\n      <td>-35.569153</td>\n      <td>-40.711327</td>\n      <td>-43.475456</td>\n      <td>-43.747631</td>\n      <td>-41.566544</td>\n      <td>-37.108936</td>\n      <td>-30.667849</td>\n      <td>-22.635021</td>\n      <td>...</td>\n      <td>34.883457</td>\n      <td>28.192152</td>\n      <td>15.495848</td>\n      <td>-2.578500</td>\n      <td>-24.737413</td>\n      <td>-49.127632</td>\n      <td>-73.555237</td>\n      <td>-95.766106</td>\n      <td>-113.732628</td>\n      <td>-125.915459</td>\n    </tr>\n    <tr>\n      <th>8_7</th>\n      <td>-33.967102</td>\n      <td>-32.017540</td>\n      <td>-27.452972</td>\n      <td>-20.603409</td>\n      <td>-12.023408</td>\n      <td>-2.387321</td>\n      <td>7.625940</td>\n      <td>17.436592</td>\n      <td>26.651592</td>\n      <td>35.110722</td>\n      <td>...</td>\n      <td>76.403763</td>\n      <td>70.120720</td>\n      <td>62.356373</td>\n      <td>53.907246</td>\n      <td>45.582462</td>\n      <td>38.119202</td>\n      <td>32.112026</td>\n      <td>27.962679</td>\n      <td>25.867680</td>\n      <td>25.843983</td>\n    </tr>\n    <tr>\n      <th>8_8</th>\n      <td>16.815691</td>\n      <td>10.192864</td>\n      <td>5.472429</td>\n      <td>2.710255</td>\n      <td>1.658299</td>\n      <td>1.842864</td>\n      <td>2.688516</td>\n      <td>3.643951</td>\n      <td>4.276560</td>\n      <td>4.325038</td>\n      <td>...</td>\n      <td>-55.594746</td>\n      <td>-46.241917</td>\n      <td>-34.735180</td>\n      <td>-21.981701</td>\n      <td>-8.764092</td>\n      <td>4.280690</td>\n      <td>16.642647</td>\n      <td>27.897211</td>\n      <td>37.658298</td>\n      <td>45.543083</td>\n    </tr>\n    <tr>\n      <th>8_9</th>\n      <td>23.275391</td>\n      <td>5.198435</td>\n      <td>-12.615696</td>\n      <td>-28.700695</td>\n      <td>-41.896564</td>\n      <td>-51.436348</td>\n      <td>-56.966782</td>\n      <td>-58.497654</td>\n      <td>-56.310261</td>\n      <td>-50.860695</td>\n      <td>...</td>\n      <td>54.887783</td>\n      <td>47.968651</td>\n      <td>40.608437</td>\n      <td>32.969738</td>\n      <td>25.212347</td>\n      <td>17.495827</td>\n      <td>9.981479</td>\n      <td>2.834087</td>\n      <td>-3.782435</td>\n      <td>-9.720043</td>\n    </tr>\n  </tbody>\n</table>\n<p>170 rows × 8000 columns</p>\n</div>"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat([train, test])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[1.  , 0.  ],\n       [1.  , 0.  ],\n       [1.  , 0.  ],\n       [1.  , 0.  ],\n       [1.  , 0.  ],\n       [1.  , 0.  ],\n       [1.  , 0.  ],\n       [1.  , 0.  ],\n       [1.  , 0.  ],\n       [1.  , 0.  ],\n       [1.  , 0.  ],\n       [1.  , 0.  ],\n       [1.  , 0.  ],\n       [1.  , 0.  ],\n       [1.  , 0.  ],\n       [1.  , 0.  ],\n       [1.  , 0.  ],\n       [1.  , 0.  ],\n       [1.  , 0.  ],\n       [1.  , 0.  ],\n       [1.  , 0.  ],\n       [1.  , 0.  ],\n       [1.  , 0.  ],\n       [1.  , 0.  ],\n       [1.  , 0.  ],\n       [1.  , 0.  ],\n       [1.  , 0.  ],\n       [1.  , 0.  ],\n       [1.  , 0.  ],\n       [1.  , 0.  ],\n       [1.  , 0.  ],\n       [1.  , 0.  ],\n       [1.  , 0.  ],\n       [1.  , 0.  ],\n       [1.  , 0.  ],\n       [1.  , 0.  ],\n       [1.  , 0.  ],\n       [1.  , 0.  ],\n       [1.  , 0.  ],\n       [1.  , 0.  ],\n       [1.  , 0.  ],\n       [1.  , 0.  ],\n       [1.  , 0.  ],\n       [1.  , 0.  ],\n       [1.  , 0.  ],\n       [1.  , 0.  ],\n       [1.  , 0.  ],\n       [1.  , 0.  ],\n       [1.  , 0.  ],\n       [1.  , 0.  ],\n       [1.  , 0.  ],\n       [1.  , 0.  ],\n       [1.  , 0.  ],\n       [1.  , 0.  ],\n       [1.  , 0.  ],\n       [1.  , 0.  ],\n       [1.  , 0.  ],\n       [1.  , 0.  ],\n       [1.  , 0.  ],\n       [1.  , 0.  ],\n       [1.  , 0.  ],\n       [1.  , 0.  ],\n       [1.  , 0.  ],\n       [1.  , 0.  ],\n       [1.  , 0.  ],\n       [1.  , 0.  ],\n       [1.  , 0.  ],\n       [1.  , 0.  ],\n       [1.  , 0.  ],\n       [1.  , 0.  ],\n       [0.06, 0.94],\n       [0.03, 0.97],\n       [0.01, 0.99],\n       [0.12, 0.88],\n       [0.09, 0.91],\n       [0.1 , 0.9 ],\n       [0.12, 0.88],\n       [0.01, 0.99],\n       [0.01, 0.99],\n       [0.04, 0.96],\n       [0.06, 0.94],\n       [0.1 , 0.9 ],\n       [0.03, 0.97],\n       [0.03, 0.97],\n       [0.09, 0.91],\n       [0.01, 0.99],\n       [0.09, 0.91],\n       [0.03, 0.97],\n       [0.05, 0.95],\n       [0.02, 0.98],\n       [1.  , 0.  ],\n       [1.  , 0.  ],\n       [1.  , 0.  ],\n       [1.  , 0.  ],\n       [1.  , 0.  ],\n       [1.  , 0.  ],\n       [1.  , 0.  ],\n       [1.  , 0.  ],\n       [1.  , 0.  ],\n       [1.  , 0.  ],\n       [1.  , 0.  ],\n       [1.  , 0.  ],\n       [1.  , 0.  ],\n       [1.  , 0.  ],\n       [1.  , 0.  ],\n       [1.  , 0.  ],\n       [1.  , 0.  ],\n       [1.  , 0.  ],\n       [1.  , 0.  ],\n       [1.  , 0.  ],\n       [1.  , 0.  ],\n       [1.  , 0.  ],\n       [1.  , 0.  ],\n       [1.  , 0.  ],\n       [1.  , 0.  ],\n       [1.  , 0.  ],\n       [1.  , 0.  ],\n       [1.  , 0.  ],\n       [1.  , 0.  ],\n       [1.  , 0.  ],\n       [1.  , 0.  ],\n       [1.  , 0.  ],\n       [1.  , 0.  ],\n       [1.  , 0.  ],\n       [1.  , 0.  ],\n       [1.  , 0.  ],\n       [1.  , 0.  ],\n       [1.  , 0.  ],\n       [1.  , 0.  ],\n       [1.  , 0.  ],\n       [1.  , 0.  ],\n       [1.  , 0.  ],\n       [1.  , 0.  ],\n       [1.  , 0.  ],\n       [1.  , 0.  ],\n       [1.  , 0.  ],\n       [1.  , 0.  ],\n       [1.  , 0.  ],\n       [1.  , 0.  ],\n       [1.  , 0.  ],\n       [1.  , 0.  ],\n       [1.  , 0.  ],\n       [1.  , 0.  ],\n       [1.  , 0.  ],\n       [1.  , 0.  ],\n       [1.  , 0.  ],\n       [1.  , 0.  ],\n       [1.  , 0.  ],\n       [1.  , 0.  ],\n       [1.  , 0.  ],\n       [1.  , 0.  ],\n       [1.  , 0.  ],\n       [1.  , 0.  ],\n       [1.  , 0.  ],\n       [1.  , 0.  ],\n       [1.  , 0.  ],\n       [1.  , 0.  ],\n       [1.  , 0.  ],\n       [1.  , 0.  ],\n       [1.  , 0.  ],\n       [0.  , 1.  ],\n       [0.03, 0.97],\n       [0.05, 0.95],\n       [0.05, 0.95],\n       [0.06, 0.94],\n       [0.02, 0.98],\n       [0.03, 0.97],\n       [0.03, 0.97],\n       [0.02, 0.98],\n       [0.07, 0.93]])"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier(random_state=42)\n",
    "rf.fit(pca.transform(pd.concat([train, test])), [0] * 70 + [1] * 20 + [0] * 70 + [1] * 10)\n",
    "proba = rf.predict_proba(pca.transform(pd.concat([train, test])), )\n",
    "proba"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "data": {
      "text/plain": "array([0.05796225, 0.01832271, 0.0473746 , 0.12397487, 0.04696468,\n       0.04987433, 0.12500623, 0.03113295, 0.05116806, 0.15117179,\n       0.0784284 , 0.0355981 , 0.05759811, 0.04443241, 0.04211371,\n       0.02002009, 0.01885673])"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.feature_importances_"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[ -4465.509  ,    497.18585,   -356.95532, ...,   -606.6225 ,\n           207.3414 ,  -1032.1714 ],\n       [ -4465.4653 ,    497.1189 ,   -356.8735 , ...,   -606.3855 ,\n           208.13332,  -1032.5629 ],\n       [ -4465.5527 ,    497.06113,   -356.8011 , ...,   -606.1006 ,\n           208.02843,  -1032.4032 ],\n       ...,\n       [-52888.305  ,  42243.137  ,  49385.836  , ...,  -9422.124  ,\n         -9002.82   ,  -7775.862  ],\n       [-19416.488  , -63245.86   , -49537.777  , ...,    241.39972,\n          4132.109  ,   -176.80858],\n       [-14277.77   , -32006.13   ,   4917.073  , ...,  10931.992  ,\n         21978.457  ,  -2526.786  ]], dtype=float32)"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca.transform(pd.concat([train, test]))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
